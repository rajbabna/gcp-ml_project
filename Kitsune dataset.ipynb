{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26e564-321e-4e3d-ba76-d939fa35a44d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kitsune+network+attack+dataset.zip: 19.0GB [05:12, 60.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File downloaded at: ./datasets/kitsune+network+attack+dataset.zip\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Replace these values with your specific ones\n",
    "url = \"https://archive.ics.uci.edu/static/public/516/kitsune+network+attack+dataset.zip\"\n",
    "folder_path = \"./datasets\"\n",
    "file_name = \"kitsune+network+attack+dataset.zip\"\n",
    "\n",
    "def download_with_progress(url, file_path):\n",
    "    # Open the URL\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        # Get the file size from the header, if available\n",
    "        file_size_header = response.headers.get('Content-Length')\n",
    "        if file_size_header is not None:\n",
    "            file_size = int(file_size_header)\n",
    "        else:\n",
    "            file_size = None\n",
    "        \n",
    "        # Create a progress bar\n",
    "        with tqdm(total=file_size, unit='B', unit_scale=True, desc=file_name) as pbar:\n",
    "            # Download the file in chunks\n",
    "            with open(file_path, 'wb') as file, urllib.request.urlopen(url) as response:\n",
    "                buffer_size = 1024 * 8\n",
    "                while True:\n",
    "                    chunk = response.read(buffer_size)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    file.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "\n",
    "def download_and_extract(url, folder_path, file_name):\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    # Combine folder path and file name to get the full path\n",
    "    full_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Download the file with progress\n",
    "    download_with_progress(url, full_path)\n",
    "    \n",
    "    print(f\"\\nFile downloaded at: {full_path}\")\n",
    "    \n",
    "    # Extract the contents of the zip file\n",
    "    with ZipFile(full_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(folder_path)\n",
    "    \n",
    "    print(f\"File extracted to: {folder_path}\")\n",
    "\n",
    "# Call the function with the specified values\n",
    "download_and_extract(url, folder_path, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2956d91a-68de-494c-bdfe-8bd755280e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cf6ee9-cc52-4279-984d-a2038d544da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting files: 100%|██████████| 37/37 [02:35<00:00,  4.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_all_files_with_progress(zip_file_path, extract_folder):\n",
    "    with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        # Get the list of files in the ZIP archive\n",
    "        file_list = zip_ref.namelist()\n",
    "        \n",
    "        # Create a progress bar\n",
    "        with tqdm(total=len(file_list), desc=\"Extracting files\") as pbar:\n",
    "            # Extract all files to the specified folder\n",
    "            for file in file_list:\n",
    "                zip_ref.extract(file, extract_folder)\n",
    "                pbar.update(1)\n",
    "\n",
    "# Example usage:\n",
    "zip_file_path = \"./datasets/kitsune+network+attack+dataset.zip\"  # Replace with the path to your ZIP file\n",
    "extract_folder = \"./datasets/extracted\"  # Replace with the desired extraction folder\n",
    "\n",
    "# Ensure the extraction folder exists\n",
    "if not os.path.exists(extract_folder):\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "# Call the function to extract all files with progress\n",
    "extract_all_files_with_progress(zip_file_path, extract_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a37c7ec-348d-4097-a27c-9116829df8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting files: 100%|██████████| 37/37 [02:47<00:00,  4.54s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_all_files_with_progress(zip_file_path, extract_folder):\n",
    "    with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        # Get the list of files in the ZIP archive\n",
    "        file_list = zip_ref.namelist()\n",
    "        \n",
    "        # Create a progress bar for the outer extraction\n",
    "        with tqdm(total=len(file_list), desc=\"Extracting files\") as pbar_outer:\n",
    "            # Extract all files to the specified folder\n",
    "            for file in file_list:\n",
    "                zip_ref.extract(file, extract_folder)\n",
    "                pbar_outer.update(1)\n",
    "\n",
    "                # Check if the extracted file is another compressed archive (ZIP)\n",
    "                if file.lower().endswith('.zip' or '.gz'):\n",
    "                    # Extract files from the nested ZIP archive recursively\n",
    "                    nested_zip_path = os.path.join(extract_folder, file)\n",
    "                    nested_extract_folder = os.path.join(extract_folder, os.path.splitext(file)[0])\n",
    "                    extract_all_files_with_progress(nested_zip_path, nested_extract_folder)\n",
    "\n",
    "                    # Update the progress bar for the nested extraction\n",
    "                    pbar_outer.set_postfix_str(f\"Nested Extraction: {file}\", refresh=True)\n",
    "\n",
    "# Example usage:\n",
    "zip_file_path = \"./datasets/kitsune+network+attack+dataset.zip\"  # Replace with the path to your ZIP file\n",
    "extract_folder = \"./datasets/extracted\"  # Replace with the desired extraction folder\n",
    "\n",
    "# Ensure the extraction folder exists\n",
    "if not os.path.exists(extract_folder):\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "# Call the function to extract all files with progress, including nested ZIP archives\n",
    "extract_all_files_with_progress(zip_file_path, extract_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d749d87-4de5-43dd-ab3f-a0637693aeee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting .gz files:  67%|██████▋   | 2/3 [00:03<00:01,  1.99s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_all_gz_files(folder_path, extract_folder):\n",
    "    # Create the extraction folder if it doesn't exist\n",
    "    if not os.path.exists(extract_folder):\n",
    "        os.makedirs(extract_folder)\n",
    "\n",
    "    # Get a list of all files in the folder\n",
    "    file_list = [file for file in os.listdir(folder_path) if file.lower().endswith('.gz')]\n",
    "\n",
    "    # Create a progress bar\n",
    "    with tqdm(total=len(file_list), desc=\"Extracting .gz files\") as pbar:\n",
    "        # Extract each .gz file\n",
    "        for file in file_list:\n",
    "            input_path = os.path.join(folder_path, file)\n",
    "            output_path = os.path.join(extract_folder, os.path.splitext(file)[0])\n",
    "\n",
    "            with gzip.open(input_path, 'rb') as gz_file, open(output_path, 'wb') as output_file:\n",
    "                output_file.write(gz_file.read())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "# Example usage:\n",
    "input_folder = \"./datasets/extracted/active_wiretap\"  # Replace with the path to your folder containing .gz files\n",
    "output_folder = \"./datasets/extracted/active_wiretap/extracted\"  # Replace with the desired extraction folder\n",
    "\n",
    "# Call the function to extract all .gz files with progress\n",
    "extract_all_gz_files(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51131ff-8409-4ee9-bdbc-74316e81d2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
